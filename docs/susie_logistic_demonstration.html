<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Andrew Goldstein" />


<title>susieR Logistic Regression GLM</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">susieR_Logistic_wflow</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">susieR Logistic Regression GLM</h1>
<h4 class="author"><em>Andrew Goldstein</em></h4>
<h4 class="date"><em>December 3, 2018</em></h4>

</div>


<p><strong>Last updated:</strong> 2018-12-08</p>
<strong>workflowr checks:</strong> <small>(Click a bullet for more information)</small>
<ul>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>R Markdown file:</strong> up-to-date </summary></p>
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Environment:</strong> empty </summary></p>
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Seed:</strong> <code>set.seed(20181203)</code> </summary></p>
<p>The command <code>set.seed(20181203)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Session information:</strong> recorded </summary></p>
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Repository version:</strong> <a href="https://github.com/andrewg3311/susieR_logistic_wflow/tree/14106009dea2ffa3593d7ed24d8efc6611bd8fed" target="_blank">1410600</a> </summary></p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    analysis/susie_logistic_demonstration_cache/

</code></pre>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes. </details>
</li>
</ul>
<details> <summary> <small><strong>Expand here to see past versions:</strong></small> </summary>
<ul>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
File
</th>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
<th style="text-align:left;">
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/14106009dea2ffa3593d7ed24d8efc6611bd8fed/analysis/susie_logistic_demonstration.Rmd" target="_blank">1410600</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
<td style="text-align:left;">
Adding comparison w/ regular SuSiE
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/susie_logistic_demonstration.html" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/42526135b69beb45c98e245e420d438487ad298c/analysis/susie_logistic_demonstration.Rmd" target="_blank">4252613</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
<td style="text-align:left;">
Fixing X in easy simulations to have variance 1 and be independent (not orthonormal), fixing bug in while loop, updating
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/1aa009288a25e92003d264ab06361c9345758158/docs/susie_logistic_demonstration.html" target="_blank">1aa0092</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-07
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/8ce1cac33ce2975c9d3a64b29308b7a4aaa48cd1/analysis/susie_logistic_demonstration.Rmd" target="_blank">8ce1cac</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-07
</td>
<td style="text-align:left;">
Some minor formatting changes
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/baca7a39d72486486744a17246370c5d64c931ac/docs/susie_logistic_demonstration.html" target="_blank">baca7a3</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-07
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/3f0a7c11eebe5a3de1ad8f4ec04992eae53bf520/analysis/susie_logistic_demonstration.Rmd" target="_blank">3f0a7c1</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-07
</td>
<td style="text-align:left;">
Adding note that same phase change happens w/ regular SuSiE
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/c4bcd3a53e858a5bc4df18124c3d242cff1b0bad/docs/susie_logistic_demonstration.html" target="_blank">c4bcd3a</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11b93732af6e3eaca54b359bf209a9239c5ef2c3/analysis/susie_logistic_demonstration.Rmd" target="_blank">11b9373</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
<td style="text-align:left;">
Fixing figure numbering
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/23eac4fe33dc8feacf7b074a8c6492003d934bf4/docs/susie_logistic_demonstration.html" target="_blank">23eac4f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/eaeef13ebb7a2e26ad7992cad6d859794b4395e9/analysis/susie_logistic_demonstration.Rmd" target="_blank">eaeef13</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
<td style="text-align:left;">
Add second simple example with L = 2
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/e617aaaab8cc40c5bc3061ef4b412599e9946993/docs/susie_logistic_demonstration.html" target="_blank">e617aaa</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/22993c64888be5d421d9e5aae356cb7cc57e0574/analysis/susie_logistic_demonstration.Rmd" target="_blank">22993c6</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
<td style="text-align:left;">
Update intercept estimation, and add simpler example
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/5f4bc45f8d6cec4103656bc39056a3532277906a/docs/susie_logistic_demonstration.html" target="_blank">5f4bc45</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/4cb348960a6e4447ba313a6b959c117183dcce06/analysis/susie_logistic_demonstration.Rmd" target="_blank">4cb3489</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
<td style="text-align:left;">
Update intercept estimation, and add simpler example
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/8ff7107fba180866a7b9104ed329a255c9d4b1e3/docs/susie_logistic_demonstration.html" target="_blank">8ff7107</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/c40eeff54394a4bae8f58ad634e16bd0bf4c6beb/analysis/susie_logistic_demonstration.Rmd" target="_blank">c40eeff</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Re-running to fix figures
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/939555fb9135377b9829bc98dfe68bd82f83f425/docs/susie_logistic_demonstration.html" target="_blank">939555f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/e0c6faf38ceff33c5f2b756a9f755f196c86629e/analysis/susie_logistic_demonstration.Rmd" target="_blank">e0c6faf</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Re-running to fix figures
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/c82fc0f7f26bce1e993359e4b34e4f15065c19be/docs/susie_logistic_demonstration.html" target="_blank">c82fc0f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/a82ffad5e95b7fa812ec88e3d60dc024ba5beed4/docs/susie_logistic_demonstration.html" target="_blank">a82ffad</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/366c1b310a552d18812efc87e4c33e1a1647c99a/docs/susie_logistic_demonstration.html" target="_blank">366c1b3</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/481510b0eeb2efe6373950a8b25565e42a19c0d2/docs/susie_logistic_demonstration.html" target="_blank">481510b</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/f4f10e99276de0bae0888e214b26bc2481687000/analysis/susie_logistic_demonstration.Rmd" target="_blank">f4f10e9</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Add signal level test with genotype-style data (X_ij = 0, 1, 2)
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/a96c6bb7dbd0e50ce88f902330b40aeea5b8e03e/docs/susie_logistic_demonstration.html" target="_blank">a96c6bb</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/e5e14dafd5c5052261ace803f814974ad556867a/analysis/susie_logistic_demonstration.Rmd" target="_blank">e5e14da</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Increase sample size n := 1000 for signal level tests
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/ea80ce25c0fa7ae0cffdaad323cfb043c61ab3b1/docs/susie_logistic_demonstration.html" target="_blank">ea80ce2</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/7e724ccabfaf00fdedbb724d5b2b6eb0a468ecd4/analysis/susie_logistic_demonstration.Rmd" target="_blank">7e724cc</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Specify size of the problem for signal size exploration
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/378e04e430e0c631b1658dbee6b5aee1d5b63f3c/docs/susie_logistic_demonstration.html" target="_blank">378e04e</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/88a7560a22c33b562f6a82fe74191796ee9ae07f/analysis/susie_logistic_demonstration.Rmd" target="_blank">88a7560</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Updated to add a test at different noise levels, and add a blurb about fitting the intercept
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/5ae2c6c9f4add64e3c1239f488e73a5f5ebc227f/docs/susie_logistic_demonstration.html" target="_blank">5ae2c6c</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/2364416ad92e50a701d02e68b889e12c819120b8/analysis/susie_logistic_demonstration.Rmd" target="_blank">2364416</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
<td style="text-align:left;">
Updating to add intercept estimation, and more efficiently calculate the fixed portion for each SER
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/41527d2d87e41628876751f25975fbc8d4752b83/docs/susie_logistic_demonstration.html" target="_blank">41527d2</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/d42fc1c69297b86564123833324be60ed014c8c3/analysis/susie_logistic_demonstration.Rmd" target="_blank">d42fc1c</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
<td style="text-align:left;">
Making plots bigger, and cache slow-running code
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/b5ab5f4b0a163af70efa5292e554926b538a1f8f/docs/susie_logistic_demonstration.html" target="_blank">b5ab5f4</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/a60317c866145b4ce9f78191829e56d3c833df5e/analysis/susie_logistic_demonstration.Rmd" target="_blank">a60317c</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
<td style="text-align:left;">
Adding hard example
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/60b24de8f6e2b8bb81d1ba62b66e9ffcc5fca4f8/docs/susie_logistic_demonstration.html" target="_blank">60b24de</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/b7e6c6bf33f2f0617b8cb49d6a789b9a725032ce/analysis/susie_logistic_demonstration.Rmd" target="_blank">b7e6c6b</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
<td style="text-align:left;">
Change knitr results option to default (markup)
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/andrewg3311/susieR_logistic_wflow/ba6830a1532b3933377dce255bba0699c61b63a3/docs/susie_logistic_demonstration.html" target="_blank">ba6830a</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/49a07a45bacf035dff6662079de30635aaacd02b/analysis/susie_logistic_demonstration.Rmd" target="_blank">49a07a4</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
<td style="text-align:left;">
Adding logistic demonstration
</td>
</tr>
</tbody>
</table>
</ul>
<p></details></p>
<hr />
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>This page aims to explore an analog to SuSiE applied to 0/1 data using logistic regression. The basic idea is to replace the Single Effect Regression (SER) step in the Iterative Bayesian Forward Selection (IBFS) algorithm with an analogous logistic regression step.</p>
<p>Our response is <span class="math inline">\(\mathbf{y} \in \mathbb{R}^n\)</span>, and our covariates are <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n \times p}\)</span>.</p>
<div id="ser-model" class="section level2">
<h2>SER Model</h2>
<p>In the standard SuSiE model, the following SER regression model is used: <span class="math display">\[
\begin{aligned}
\mathbf{y} = \mathbf{Xb} + \mathbf{e} \\
\mathbf{e} \sim \mathcal{N}(0, \sigma^2 I_n) \\
\mathbf{b} = \mathbf{\gamma}b \\
\mathbf{\gamma} \sim \text{Mult}(1, \mathbf{\pi}) \\
b \sim \mathcal{N}(0, \sigma_0^2)
\end{aligned}
\]</span></p>
<p>From this model, the standard OLS estimates (also the MLE) for <span class="math inline">\(b_j\)</span> is found using <span class="math inline">\(p\)</span> independent simple linear regressions (fit without an intercept), <span class="math inline">\(\hat{b_j}(\mathbf{y}, \mathbf{x_j}) = (\mathbf{x_j^Tx_j})^{-1}\mathbf{x_j^Ty}\)</span>, with variance <span class="math inline">\(\sigma_{MLE_j}^2 = \sigma^2 (\mathbf{x_j^Tx_j})^{-1}\)</span>. The posterior distribution for <span class="math inline">\(b_j\)</span> given <span class="math inline">\(\gamma_j = 1\)</span> is then <span class="math display">\[
\begin{aligned}
b|\gamma_j = 1, \mathbf{y}, \sigma^2, \sigma_0^2 \sim \mathcal{N}(\mu_{1j}, \sigma_{1j}^2) \\
\sigma_{1j}^2 = \frac{1}{1 / \sigma_{MLE_j}^2 + 1 / \sigma_0^2} \\
\mu_{1j} = \frac{1 / \sigma_{MLE_j}^2}{1 / \sigma_{MLE_j}^2 + 1 / \sigma_0^2} \hat{b_j}(\mathbf{y}, \mathbf{x_j}) + \frac{1 / \sigma_0^2}{1 / \sigma_{MLE_j}^2 + 1 / \sigma_0^2} 0 = \frac{\sigma_{1j}^2}{\sigma_{MLE_j}^2} \hat{b_j}(\mathbf{y}, \mathbf{x_j})
\end{aligned}
\]</span></p>
<p>The Bayes Factor is then calculated as <span class="math display">\[
\frac{p(\hat{b_j}(\mathbf{y}, \mathbf{x_j}) | b_j \sim \mathcal{N}(0, \sigma_0^2))}{p(\hat{b_j}(\mathbf{y}, \mathbf{x_j}) | b_j = 0)}
\]</span></p>
<p>Since <span class="math inline">\(\hat{b_j}(\mathbf{y}, \mathbf{x_j}) \sim \mathcal{N}(b_j, \sigma_{MLE_j}^2) = b_j + \mathcal{N}(0, \sigma_{MLE_j}^2)\)</span>, we have that <span class="math display">\[
\begin{aligned}
\hat{b_j}(\mathbf{y}, \mathbf{x_j}) \sim_{M_{1j}} \mathcal{N}(0, \sigma_0^2 + \sigma_{MLE_j}^2) \\
\hat{b_j}(\mathbf{y}, \mathbf{x_j}) \sim_{M_{0_j}} \mathcal{N}(0, \sigma_{MLE_j}^2) \\
\end{aligned}
\]</span> where <span class="math inline">\(M_{1j}\)</span> is the specified model where <span class="math inline">\(b_j\)</span> is the non-zero element, and <span class="math inline">\(M_{0j}\)</span> is the null model (i.e. the model in which <span class="math inline">\(b_j = 0\)</span>). From this, we see that the Bayes Factor is simply a ratio of normal densities.</p>
<p>Then, we calculate the vector of PIPs <span class="math inline">\(\alpha\)</span> as: <span class="math display">\[
\alpha_j = \frac{\text{BF}(\mathbf{y}, \mathbf{x_j}; \sigma^2, \sigma_0^2) \pi_j}{\sum_{k = 1}^p \text{BF}(\mathbf{y}, \mathbf{x_k}; \sigma^2, \sigma_0^2) \pi_k}
\]</span></p>
<p>Here, the following adjusted model is considered: <span class="math display">\[
\begin{aligned}
\mathbf{y} \sim \text{Bern}\Bigg(\frac{e^\mathbf{Xb}}{1 + e^{\mathbf{Xb}}}\Bigg) \quad \text{(element-wise)} \\
\mathbf{b} = \gamma b \\
\mathbf{\gamma} \sim \text{Mult}(1, \mathbf{\pi}) \\
b \sim \mathcal{N}(0, \sigma_0^2)
\end{aligned}
\]</span></p>
<p>From here, instead of computing the closed-form solution for <span class="math inline">\(\hat{b_j}(\mathbf{y}, \mathbf{x_j})\)</span>, we perform a logistic regression with R’s <code>glm</code> function in order to calculate <span class="math inline">\(\hat{b_j}(\mathbf{y}, \mathbf{x_j})\)</span> and <span class="math inline">\(\sigma_{MLE_j}^2\)</span> for each of the <span class="math inline">\(p\)</span> single-variable logistic regressions (fit without an intercept).</p>
<p>The rest follows as outlined above for the regular SER model.</p>
</div>
<div id="full-model" class="section level2">
<h2>Full Model</h2>
<p>The full SuSiE model is as follows: <span class="math display">\[
\begin{aligned}
\mathbf{y} = \mathbf{Xb} + \mathbf{e} \\
\mathbf{e} \sim \mathcal{N}(0, \sigma^2 I_n) \\
\mathbf{b} = \sum_{l = 1}^L \mathbf{b}_l \\
\mathbf{b}_l = \gamma_l b_l \quad (\text{independently for } l = 1, \dots, L) \\
\gamma_l \sim \text{Mult}(1, \mathbf{\pi}) \\
b_l \sim \mathcal{N}(0, \sigma_{0l}^2)
\end{aligned}
\]</span></p>
<p>The IBFS algorithm is then applied. In this algorithm, we iterate over <span class="math inline">\(l \in \{1, \dots, L\}\)</span> and perform our SER step on the residuals, <span class="math inline">\(\mathbf{r_l} \equiv \mathbf{y} - \sum_{l&#39; \ne l} \mathbf{X\bar{b}}_{l&#39;}\)</span>, to get the vectors <span class="math inline">\(\alpha_l, \mu_{1l}, \sigma_{1l}\)</span>. We then set <span class="math inline">\(\mathbf{\bar{b}}_l := \alpha_l \circ \mu_{1l}\)</span> (Schur product).</p>
<p>Here, the following adjusted model is considered: <span class="math display">\[
\begin{aligned}
\mathbf{y} \sim \text{Bern}\Bigg(\frac{e^\mathbf{Xb}}{1 + e^{\mathbf{Xb}}}\Bigg) \quad \text{(element-wise)} \\
\mathbf{b} = \sum_{l = 1}^L \mathbf{b}_l \\
\mathbf{b}_l = \gamma_l b_l \quad (\text{independently for } l = 1, \dots, L) \\
\gamma_l \sim \text{Mult}(1, \mathbf{\pi}) \\
b_l \sim \mathcal{N}(0, \sigma_{0l}^2)
\end{aligned}
\]</span></p>
<p>We modify the IBFS algorithm to use the analogs from this model. The main difference is that we can no longer perform SER on the residuals, since the residuals don’t really make sense in the logistic setting.</p>
<p>However, noting that the following regressions are equivalent (where <span class="math inline">\(\sim\)</span> is interpreted as the regression formula, as in <code>lm</code> or <code>glm</code>), we have motivation for altering the IBFS algorithm: <span class="math display">\[ 
\mathbf{r}_l \sim \mathbf{Xb}_l  \iff \mathbf{y} - \sum_{l&#39; \ne l} \mathbf{X\bar{b}}_{l&#39;} \sim \mathbf{Xb}_l  \iff \mathbf{y} \sim \mathbf{Xb}_l + \text{offset}(\sum_{l&#39; \ne l} \mathbf{X\bar{b}}_{l&#39;})
\]</span> Here, <code>offset</code> is the function in R that forces the coefficient for the predictor to be 1.</p>
<p>Thus, in our modified logistic version, when fitting the SER each iteration, we can simply fit:</p>
<pre><code>glm(Y ~ X[, j] + offset(fixed), family = &quot;binomial&quot;)</code></pre>
<p>separately for each <span class="math inline">\(j \in \{1, \dots, p\}\)</span>, where <code>fixed</code> is <span class="math inline">\(\sum_{l&#39; \ne l} \mathbf{X\bar{b}}_{l&#39;}\)</span>.</p>
<div id="a-note-on-the-intercept" class="section level3">
<h3>A Note on the Intercept</h3>
<p>In regular SuSiE, we can center our covariates and response to avoid fitting the intercept. Since our data is now 0/1, we can no longer center our response. Instead, we can fit an intercept in our IBFS.</p>
<p>However, we note that centering X and Y at the start of the procedure and not fitting an intercept in each SER is equivalent to not centering X and Y and fitting an intercept in each SER step. As a result, in the logistic case, we do fit an intercept in each logistic SER.</p>
</div>
</div>
</div>
<div id="adjustments-to-susie-code" class="section level1">
<h1>Adjustments to SuSiE Code</h1>
<p>The code below is a simplistic implementation of the above ideas.</p>
<p>(Note: Not all code is needed, some vestigial components from a copy-paste job from susieR)</p>
<pre class="r"><code>### NOTE: This is basic code, and I did not attempt to mirror the level of numerical sophistication in the susie functions
### If this idea is worth pursuing further, then this code can be improved

susie_logistic = function(Y, X, L = 10, V = 1, prior_weights = NULL, tol = 1e-3, maxit = 1000, intercept = TRUE) {
  
  p = ncol(X)
  n = nrow(X)
  
  # place to store posterior info for each l = 1, ..., L
  post_alpha = matrix(NA, nrow = p, ncol = L)
  post_mu = matrix(NA, nrow = p, ncol = L)
  post_sigma = matrix(NA, nrow = p, ncol = L)
  post_info = list(post_alpha = post_alpha, post_mu = post_mu, post_sigma = post_sigma)

  beta_post_init = matrix(Inf, nrow = p, ncol = L) # initialize
  beta_post_init2 = beta_post_init
  beta_post = matrix(0, nrow = p, ncol = L)
  
  fixed = rep(0, n) # fixed portion, estimated from l&#39; != l other SER models
  
  iter = 0
  while((norm(beta_post - beta_post_init, &quot;1&quot;) &gt; tol) &amp; (norm(beta_post - beta_post_init2, &quot;1&quot;) &gt; tol)) { # repeat until posterior means converge (ELBO not calculated here, so use this convergence criterion instead)
    beta_post_init2 = beta_post_init # store from 2 iterations ago
    beta_post_init = beta_post
      
    for (l in 1:L) {
      
      # below is old (inefficient) calculation of the fixed portion
      #fixed = rowSums(X %*% beta_post[, -l]) + int.coef # fixed portion from previous estimates (add intercept portion as well)
      fixed = fixed - (X %*% beta_post[, l]) # remove effect from previous iteration
      
      SER_logistric_l = single_effect_regression_logistic(Y, X, V, prior_weights, FALSE, fixed, intercept)
      # store
      post_info$post_alpha[, l] = SER_logistric_l$alpha
      post_info$post_mu[, l] = SER_logistric_l$mu
      post_info$post_sigma[, l] = SER_logistric_l$mu2 - SER_logistric_l$mu^2
      
      # update beta_post
      beta_post[, l] = SER_logistric_l$alpha * SER_logistric_l$mu
      
      fixed = fixed + (X %*% beta_post[, l]) # add back new fixed portion
      
    }
    
    iter = iter + 1
    if (iter &gt; maxit) {
        stop(&quot;Maximum number of iterations reached&quot;)
    }
    
  }
  
  return(post_info)
  
}


# SER_logistic function
single_effect_regression_logistic = function(Y, X, V, prior_weights = NULL, optimize_V = FALSE, fixed = NULL, intercept = TRUE) {
  p = ncol(X)
  
  betahat = numeric(p)
  shat2 = numeric(p)
  
  if (is.null(fixed)) { # fixed is components from previous SER fits
    fixed = rep(0, length(Y))
  }
  
  # NOTE: could parallelize loop below if desired
  for (j in 1:p) { # logistic regression on each column of X separately
    if (intercept) {
      log.fit = glm(Y ~ X[, j] + 1 + offset(fixed), family = &quot;binomial&quot;) # fit w/ intercept
    } else {
      log.fit = glm(Y ~ X[, j] - 1 + offset(fixed), family = &quot;binomial&quot;) # fit w/out intercept
    }
    log.fit.coef = summary(log.fit)$coefficients
    # NOTE: coerces &quot;intercept&quot; to be 0 or 1 to grab relevant row of glm coefficient output
    betahat[j] = ifelse(is.na(log.fit.coef[1 + intercept, 1]), 0, log.fit.coef[1 + intercept, 1]) # beta-hat MLE (if na, just set to 0)
    shat2[j] = ifelse(is.na(log.fit.coef[1 + intercept, 2]), Inf, log.fit.coef[1 + intercept, 2]^2) # (std errof beta-hat MLE)^2 (if na, just set to Inf)
  }
  
  if (is.null(prior_weights)) {
    prior_weights = rep(1 / p, p)
  }
  
  if(optimize_V) {
    stop(&quot;Optimizing for prior variance not yet implemented for logistic case&quot;)
    #if(loglik.grad(0, betahat, shat2, prior_weights) &lt; 0) {
    #  V = 0
    #} else {
    ##V.o = optim(par=log(V),fn=negloglik.logscale,gr = negloglik.grad.logscale,betahat=betahat,shat2=shat2,prior_weights=prior_weights,method=&quot;BFGS&quot;)
    ##if(V.o$convergence!=0){
    ##  warning(&quot;optimization over prior variance failed to converge&quot;)
    ##}
    #  V.u = uniroot(negloglik.grad.logscale, c(-10, 10), extendInt = &quot;upX&quot;, betahat = betahat, shat2 = shat2, prior_weights = prior_weights)
    #  V = exp(V.u$root)
    #}
  }
  
  lbf = dnorm(betahat, 0, sqrt(V + shat2), log = TRUE) - dnorm(betahat, 0, sqrt(shat2), log = TRUE)
  #log(bf) on each SNP
  
  lbf[is.infinite(shat2)] = 0 # deal with special case of infinite shat2 (eg happens if X does not vary)
  
  maxlbf = max(lbf)
  w = exp(lbf - maxlbf) # w is proportional to BF, but subtract max for numerical stability
  # posterior prob on each SNP
  w_weighted = w * prior_weights
  weighted_sum_w = sum(w_weighted)
  alpha = w_weighted / weighted_sum_w
  post_var = 1 / ((1 / shat2) + (1 / V)) # posterior variance
  post_mean = (1 / shat2) * post_var * betahat # posterior mean
  post_mean2 = post_var + post_mean^2 # posterior second moment
  # BF for single effect model
  lbf_model = maxlbf + log(weighted_sum_w)
  # NOTE: Need to double check below
  loglik = lbf_model + log(1/2)*length(Y) # loglik of 0/1 response Y under p = .5
  return(list(alpha = alpha, mu = post_mean, mu2 = post_mean2, lbf = lbf, lbf_model = lbf_model, V = V, loglik = loglik))
}</code></pre>
</div>
<div id="demonstration" class="section level1">
<h1>Demonstration</h1>
<div id="easy-demonstration" class="section level2">
<h2>Easy Demonstration</h2>
<div id="l-1" class="section level3">
<h3>L = 1</h3>
<p>As a very easy demonstration, let <span class="math inline">\(n = 100, p = 10, L = 1\)</span>, and let all columns of <span class="math inline">\(X\)</span> be distributed <span class="math inline">\(\mathcal{N}(0, 1)\)</span>. WLOG, we let the first element of <span class="math inline">\(\mathbf{b}\)</span> be the only non-zero element. We set <span class="math inline">\(\sigma_0^2 = 1\)</span>.</p>
<p>We then simulated <span class="math inline">\(\mathbf{y}\)</span> from the specified bernoulli model, <span class="math display">\[
y_i \stackrel{\perp}{\sim} \text{Bern}\Bigg(\frac{e^{(\mathbf{Xb})_i}}{1 + e^{(\mathbf{Xb})_i}}\Bigg)
\]</span> (We do not add an intercept term here, but still fit the model with an intercept).</p>
<p>We repeat this procedure 100 times.</p>
<pre class="r"><code>set.seed(1138)

n = 100
p = 10
L = 1
V = 1
beta_true = rep(0, p)

B = 100
b_1s = numeric(B)
susie.fits.easy = list() # logistic SuSiE fits
logistic.fits.easy = list() # logistic regression fits
for (i in 1:B) {
  beta_true[1] = rnorm(1, 0, sqrt(V))
  b_1s[i] = beta_true[1]
  # make independent N(0, 1) covariates
  X = matrix(rnorm(n * p), nrow = n)
  # make response
  Y = rbinom(n, 1, exp(X %*% beta_true) / (1 + exp(X %*% beta_true)))
  susie.fits.easy[[i]] = susie_logistic(Y, X, L, V)
  logistic.fits.easy[[i]] = glm(Y ~ X, family = &quot;binomial&quot;)
}</code></pre>
<p>Figure 1 below plots the estimated value for <span class="math inline">\(\hat{b}_1 := \mu_1 \cdot \alpha_1\)</span> against the true value, where <span class="math inline">\(\mu_1\)</span> is the estimated posterior mean, and <span class="math inline">\(\alpha_1\)</span> is the estimated posterior inclusion probability. Figure 2 below plots the PIP, <span class="math inline">\(\alpha_i\)</span>, against the true value of <span class="math inline">\(b_1\)</span>.</p>
<pre class="r"><code>plot(sapply(susie.fits.easy, function(x) x$post_alpha[1] * x$post_mu[1]) ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Estimate&quot;, main = &quot;Figure 1&quot;, pch = 19)
abline(0, 1)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-3-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-3-1.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5f4bc45f8d6cec4103656bc39056a3532277906a/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-3-1.png" target="_blank">5f4bc45</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/ba6830a1532b3933377dce255bba0699c61b63a3/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-3-1.png" target="_blank">ba6830a</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>plot(sapply(susie.fits.easy, function(x) x$post_alpha[1]) ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 2&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-3-2.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-3-2.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-3-2.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5f4bc45f8d6cec4103656bc39056a3532277906a/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-3-2.png" target="_blank">5f4bc45</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
</tbody>
</table>
<p></details></p>
<p>Figure 1 shows that, in this simulation, we observe a shrinkage behavior similar to hard-thresholding (with a small thresholding value). We also see that our estimated lie pretty close to the truth. Figure 2 shows a sharp transition between a very low PIP and a PIP near 1. This sharp transition is what causes the hard-thresholding-like shrinkage we obsersve in figure 1: the posterior mean values <span class="math inline">\(\mu_1\)</span> closely match the true values for <span class="math inline">\(b_1\)</span>, but are effectively shrunk to 0 in this region by the PIP <span class="math inline">\(\alpha_i\)</span>, and are effectively untouched outside this region.</p>
<p>We can compare figure 2 with the p-values obtained from the normal logistic regressions on the same simulated data, shown in figure 3 below.</p>
<pre class="r"><code>plot(sapply(logistic.fits.easy, function(x) summary(x)$coefficients[2, 4]) ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Logistic p-value&quot;, main = &quot;Figure 3&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-4-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-4-1.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5f4bc45f8d6cec4103656bc39056a3532277906a/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-4-1.png" target="_blank">5f4bc45</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5ae2c6c9f4add64e3c1239f488e73a5f5ebc227f/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-4-1.png" target="_blank">5ae2c6c</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/ba6830a1532b3933377dce255bba0699c61b63a3/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-4-1.png" target="_blank">ba6830a</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
</tr>
</tbody>
</table>
<p></details></p>
<p>We see a similar phase transition around the same values of the true effect size, <span class="math inline">\(|b_1| \le 0.5\)</span>.</p>
<div id="caution-cycling-behavior" class="section level4">
<h4>CAUTION: Cycling Behavior</h4>
<p>I have come across a situation in which the iterative algorithm gets caught in a loop, where it cycles between 2 estimates for the coefficients.</p>
<pre class="r"><code>set.seed(1138)

n = 100
p = 10
L = 2
V = 9
beta_true = rep(0, p)

# make independent N(0, 1) covariates
X = matrix(rnorm(n * p), nrow = n)

beta_true[1] = rnorm(1, 0, sqrt(V))
beta_true[2] = rnorm(1, 0, sqrt(V))
Y = rbinom(n, 1, exp(X %*% beta_true) / (1 + exp(X %*% beta_true)))
susie.cycle = susie_logistic(Y, X, L, V)</code></pre>
<p>I have gotten around this with a more sophisticated convergence criterion (e.g. also store and compare with the estimate 2 iterations ago). However, this situation may be a cause for concern.</p>
</div>
<div id="caution-more-than-cycling-behavior" class="section level4">
<h4>CAUTION: More than cycling behavior</h4>
<p>I have also come across a situation with erratic behavior. The 7th iteration leads to crazy behavior that doesn’t converge.</p>
<pre class="r"><code>set.seed(1138)

n = 100
p = 10
L = 2
V = 9
beta_true = rep(0, p)

# make independent N(0, 1) covariates
X = matrix(rnorm(n * p), nrow = n)

B = 7
b_1s = numeric(B)
b_2s = numeric(B)
#susie.fits.easy2 = list() # logistic SuSiE fits
#logistic.fits.easy2 = list() # logistic regression fits
for (i in 1:B) {
  beta_true[1] = rnorm(1, 0, sqrt(V))
  beta_true[2] = rnorm(1, 0, sqrt(V))
  b_1s[i] = beta_true[1]
  b_2s[i] = beta_true[2]
  Y = rbinom(n, 1, exp(X %*% beta_true) / (1 + exp(X %*% beta_true)))
  #susie.fits.easy2[[i]] = susie_logistic(Y, X, L, V)
  #logistic.fits.easy2[[i]] = glm(Y ~ X, family = &quot;binomial&quot;)
}</code></pre>
<p>Increasing the maximum number of iterations sometimes solves the issue, so perhaps it’s just that convergence is slow.</p>
<p><strong>Another fix is setting <span class="math inline">\(\sigma_0^2\)</span> to be smaller. There appears to be an issue when the effect size is too large (caused by separability in the data, so our SEs are huge for our estimates</strong></p>
</div>
</div>
<div id="l-2" class="section level3">
<h3>L = 2</h3>
<p>We not repeat the same as above, except with <span class="math inline">\(L = 2, \sigma_0^2 = 1\)</span>, and the second element <span class="math inline">\(b_2\)</span> also a non-zero.</p>
<pre class="r"><code>set.seed(1138)

n = 100
p = 10
L = 2
V = 1
beta_true = rep(0, p)

B = 100
b_1s = numeric(B)
b_2s = numeric(B)
susie.fits.easy2 = list() # logistic SuSiE fits
logistic.fits.easy2 = list() # logistic regression fits
for (i in 1:B) {
  beta_true[1] = rnorm(1, 0, sqrt(V))
  beta_true[2] = rnorm(1, 0, sqrt(V))
  b_1s[i] = beta_true[1]
  b_2s[i] = beta_true[2]
  # make independent N(0, 1) covariates
  X = matrix(rnorm(n * p), nrow = n)
  # make response
  Y = rbinom(n, 1, exp(X %*% beta_true) / (1 + exp(X %*% beta_true)))
  susie.fits.easy2[[i]] = susie_logistic(Y, X, L, V, maxit = 1000)
  logistic.fits.easy2[[i]] = glm(Y ~ X, family = &quot;binomial&quot;)
}</code></pre>
<p>Figures 4(a-b) below plot the estimated value for <span class="math inline">\(\hat{b}_1 := \sum_{l = 1}^2 \mu_{l,1} \cdot \alpha_{l,1}\)</span> and <span class="math inline">\(\hat{b}_2 := \sum_{l = 1}^2 \mu_{l,2} \cdot \alpha_{l,2}\)</span> against the true value, where <span class="math inline">\(\mu_{l,i}\)</span> is the estimated posterior mean, and <span class="math inline">\(\alpha_{l,i}\)</span> is the estimated posterior inclusion probability, for entry <span class="math inline">\(i\)</span> in estimated vector <span class="math inline">\(l\)</span>. Figures 5(a-b) below plot the maximum PIP, <span class="math inline">\(\max_{l \in \{1, 2\}}\alpha_{l,i}\)</span>, against the true value of <span class="math inline">\(b_i\)</span>.</p>
<pre class="r"><code>#est_b1_max = sapply(susie.fits.easy2, function(x) x$post_alpha[1, which.max(x$post_alpha[1, ]) ]* x$post_mu[1, which.max(x$post_alpha[1, ])])

#est_b2_max = sapply(susie.fits.easy2, function(x) x$post_alpha[2, which.max(x$post_alpha[2, ]) ]* x$post_mu[2, which.max(x$post_alpha[2, ])])

est_alpha1_max = sapply(susie.fits.easy2, function(x) max(x$post_alpha[1, ]))

est_alpha2_max = sapply(susie.fits.easy2, function(x) max(x$post_alpha[2, ]))

est_b = sapply(susie.fits.easy2, function(x) rowSums(x$post_alpha * x$post_mu))

plot(est_b[1, ] ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Estimate&quot;, main = &quot;Figure 4(a) - Entry 1&quot;, pch = 19)
abline(0, 1)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-8-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-1.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5f4bc45f8d6cec4103656bc39056a3532277906a/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-1.png" target="_blank">5f4bc45</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5ae2c6c9f4add64e3c1239f488e73a5f5ebc227f/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-1.png" target="_blank">5ae2c6c</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/b5ab5f4b0a163af70efa5292e554926b538a1f8f/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-1.png" target="_blank">b5ab5f4</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>plot(est_b[2, ] ~ b_2s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Estimate&quot;, main = &quot;Figure 4(b) - Entry 2&quot;, pch = 19)
abline(0, 1)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-2.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-8-2.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-2.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5f4bc45f8d6cec4103656bc39056a3532277906a/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-2.png" target="_blank">5f4bc45</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>plot(est_alpha1_max ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 5(a) - Entry 1&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-3.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-8-3.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-3.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5f4bc45f8d6cec4103656bc39056a3532277906a/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-3.png" target="_blank">5f4bc45</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>plot(est_alpha2_max ~ b_2s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 5(b) - Entry 2&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-4.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-8-4.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-8-4.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
</tbody>
</table>
<p></details></p>
<p>We see a similar pattern as above, in the case <span class="math inline">\(L = 1\)</span>. The method is also able to detect both effects (when strong enough).</p>
<p>We can compare figures 5(a-b) with the p-values obtained from the normal logistic regressions on the same simulated data, shown in figures 6(a-b) below.</p>
<pre class="r"><code>plot(sapply(logistic.fits.easy2, function(x) summary(x)$coefficients[2, 4]) ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Logistic p-value&quot;, main = &quot;Figure 6(a) - Entry 1&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-9-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-9-1.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/c4bcd3a53e858a5bc4df18124c3d242cff1b0bad/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-9-1.png" target="_blank">c4bcd3a</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/23eac4fe33dc8feacf7b074a8c6492003d934bf4/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-9-1.png" target="_blank">23eac4f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5ae2c6c9f4add64e3c1239f488e73a5f5ebc227f/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-9-1.png" target="_blank">5ae2c6c</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-04
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/41527d2d87e41628876751f25975fbc8d4752b83/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-9-1.png" target="_blank">41527d2</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-03
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>plot(sapply(logistic.fits.easy2, function(x) summary(x)$coefficients[3, 4]) ~ b_2s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Logistic p-value&quot;, main = &quot;Figure 6(b) - Entry 2&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-9-2.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-9-2.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-9-2.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
</tbody>
</table>
<p></details></p>
<p>We see a similar phase transition around the same values of the true effect size, <span class="math inline">\(|b_i| \le 0.5\)</span>.</p>
</div>
</div>
<div id="comparison-with-regular-susie" class="section level2">
<h2>Comparison with regular SuSiE</h2>
<p>Since the logistic curve is fairly linear in the middle, results from logistic regression and linear regression are often fairly similar for moderate probability values. We can use this fact to compare this implementation of logistic SuSiE against the original SuSiE.</p>
<p>We will start from the above situation where <span class="math inline">\(n = 100, p = 10, L = 2, \sigma_0^2 = 0.5\)</span>, and the entries of X are <span class="math inline">\(X_{ij} \stackrel{iid}{\sim} \mathcal{N}(0, 1)\)</span>.</p>
<pre class="r"><code>set.seed(1138)

n = 100
p = 10
L = 2
V = 0.5
beta_true = rep(0, p)

B = 100
b_1s = numeric(B)
b_2s = numeric(B)
susie.fits.easy3 = list() # logistic SuSiE fits
regular.susie.fits.easy3 = list() # regular SuSiE fits
for (i in 1:B) {
  beta_true[1] = rnorm(1, 0, sqrt(V))
  beta_true[2] = rnorm(1, 0, sqrt(V))
  b_1s[i] = beta_true[1]
  b_2s[i] = beta_true[2]
  # make independent N(0, 1) covariates
  X = matrix(rnorm(n * p), nrow = n)
  # make response
  Y = rbinom(n, 1, exp(X %*% beta_true) / (1 + exp(X %*% beta_true)))
  susie.fits.easy3[[i]] = susie_logistic(Y, X, L, V, maxit = 1000)
  regular.susie.fits.easy3[[i]] = susie(X, Y, L = 2, scaled_prior_variance = V)
}</code></pre>
<pre><code>Error in susie(X, Y, L = 2, scaled_prior_variance = V): could not find function &quot;susie&quot;</code></pre>
<p>Figures 7(a-b) below plot the estimated logistic SuSiE value for <span class="math inline">\(\hat{b}_1 := \sum_{l = 1}^2 \mu_{l,1} \cdot \alpha_{l,1}\)</span> and <span class="math inline">\(\hat{b}_2 := \sum_{l = 1}^2 \mu_{l,2} \cdot \alpha_{l,2}\)</span> against the true value, where <span class="math inline">\(\mu_{l,i}\)</span> is the estimated posterior mean, and <span class="math inline">\(\alpha_{l,i}\)</span> is the estimated posterior inclusion probability, for entry <span class="math inline">\(i\)</span> in estimated vector <span class="math inline">\(l\)</span>.</p>
<p>Figures 8(a-b) below plot the same, but for regular SuSiE.</p>
<pre class="r"><code>par(mfrow = c(2, 2))
# logistic SuSiE
est_b_log = sapply(susie.fits.easy3, function(x) rowSums(x$post_alpha * x$post_mu))

plot(est_b_log[1, ] ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Estimate&quot;, main = &quot;Figure 7(a) - Logistic Entry 1&quot;, pch = 19)</code></pre>
<pre><code>Error in (function (formula, data = NULL, subset = NULL, na.action = na.fail, : variable lengths differ (found for &#39;b_1s&#39;)</code></pre>
<pre class="r"><code>abline(0, 1)</code></pre>
<pre><code>Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet</code></pre>
<pre class="r"><code>plot(est_b_log[2, ] ~ b_2s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Estimate&quot;, main = &quot;Figure 7(b) - Logistic Entry 2&quot;, pch = 19)</code></pre>
<pre><code>Error in (function (formula, data = NULL, subset = NULL, na.action = na.fail, : variable lengths differ (found for &#39;b_2s&#39;)</code></pre>
<pre class="r"><code>abline(0, 1)</code></pre>
<pre><code>Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet</code></pre>
<pre class="r"><code># regular SuSiE
est_b_reg = sapply(regular.susie.fits.easy3, function(x) colSums(x$alpha * x$mu))

plot(est_b_reg[1, ] ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Estimate&quot;, main = &quot;Figure 8(a) - Regular Entry 1&quot;, pch = 19)</code></pre>
<pre><code>Error in est_b_reg[1, ]: incorrect number of dimensions</code></pre>
<pre class="r"><code>abline(0, 1)</code></pre>
<pre><code>Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet</code></pre>
<pre class="r"><code>plot(est_b_reg[2, ] ~ b_2s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Estimate&quot;, main = &quot;Figure 8(b) - Regular Entry 2&quot;, pch = 19)</code></pre>
<pre><code>Error in est_b_reg[2, ]: incorrect number of dimensions</code></pre>
<pre class="r"><code>abline(0, 1)</code></pre>
<pre><code>Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet</code></pre>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>We can see that, for the estimates, regular SuSiE over-shrinks the values heavily.</p>
<p>We can also compare the PIPs estimated. Figures 9(a-b) below plot the maximum PIP from logistic SuSiE, <span class="math inline">\(\max_{l \in \{1, 2\}}\alpha_{l,i}\)</span>, against the true value of <span class="math inline">\(b_i\)</span>. Figures 10(a-b) below plot the same, for regular SuSiE.</p>
<pre class="r"><code>par(mfrow = c(2, 2))
# logistic SuSiE
est_alpha1_max_log = sapply(susie.fits.easy3, function(x) max(x$post_alpha[1, ]))

est_alpha2_max_log = sapply(susie.fits.easy3, function(x) max(x$post_alpha[2, ]))

plot(est_alpha1_max_log ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 9(a) - Logistic Entry 1&quot;, pch = 19)</code></pre>
<pre><code>Error in (function (formula, data = NULL, subset = NULL, na.action = na.fail, : variable lengths differ (found for &#39;b_1s&#39;)</code></pre>
<pre class="r"><code>plot(est_alpha2_max_log ~ b_2s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 9(b) - Logistic Entry 2&quot;, pch = 19)</code></pre>
<pre><code>Error in (function (formula, data = NULL, subset = NULL, na.action = na.fail, : variable lengths differ (found for &#39;b_2s&#39;)</code></pre>
<pre class="r"><code># regular SuSiE
est_alpha1_max_reg = sapply(regular.susie.fits.easy3, function(x) max(x$alpha[, 1]))

est_alpha2_max_reg = sapply(regular.susie.fits.easy3, function(x) max(x$alpha[, 2]))

plot(est_alpha1_max_reg ~ b_1s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 10(a) - Regular Entry 1&quot;, pch = 19)</code></pre>
<pre><code>Error in (function (formula, data = NULL, subset = NULL, na.action = na.fail, : invalid type (list) for variable &#39;est_alpha1_max_reg&#39;</code></pre>
<pre class="r"><code>plot(est_alpha2_max_reg ~ b_2s, xlab = &quot;True Effect Value&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 10(b) - Regular Entry 2&quot;, pch = 19)</code></pre>
<pre><code>Error in (function (formula, data = NULL, subset = NULL, na.action = na.fail, : invalid type (list) for variable &#39;est_alpha2_max_reg&#39;</code></pre>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>We see that the PIPs are virtually identical between the logistic case and the regular case.</p>
</div>
<div id="medium-demonstration" class="section level2">
<h2>Medium Demonstration</h2>
<p>As a medium difficulty demonstration, let <span class="math inline">\(n = 100, p = 10, L = 3, \sigma_0^2 = 5\)</span>.</p>
<p>We create the data <span class="math inline">\(\mathbf{X}\)</span> where all entries are iid standard normal. I then set the 2nd column to be identical to the 3rd, and the 7th column identical to the 6th (when running this simulation, <span class="math inline">\(b_3\)</span> and <span class="math inline">\(b_6\)</span> were generated to be non-zero, and <span class="math inline">\(b_2\)</span> and <span class="math inline">\(b_7\)</span> were generated to be 0, so this was done in the spirit of the toy example from the paper).</p>
<p>We then simulated <span class="math inline">\(\mathbf{y}\)</span> from the specified bernoulli model, <span class="math display">\[
y_i \stackrel{\perp}{\sim} \text{Bern}\Bigg(\frac{e^{(\mathbf{Xb})_i}}{1 + e^{(\mathbf{Xb})_i}}\Bigg)
\]</span></p>
<pre class="r"><code>### TEST susie_logistic
set.seed(1138)

n = 100
p = 10
L = 3
pi = rep(1 / p, p) # prior weights
V = 5 # prior variance

beta_true = rep(0, p)
for (l in 1:L) {
  b_l = rnorm(1, 0, sqrt(V))
  gamma_l = rmultinom(1, 1, pi)
  beta_l = b_l * gamma_l
  beta_true = beta_true + beta_l
}

# simulate data, induce correlations
X = matrix(rnorm(n*p, 0, 1), nrow = n, ncol = p)
X[, 2] = X[, 3]
X[, 7] = X[, 6]

# make response
Y = rbinom(n, 1, exp(X %*% beta_true + 2) / (1 + exp(X %*% beta_true + 2)))

susie.logistic.fit = susie_logistic(Y, X, L, V)</code></pre>
<p>Figure 7 below plots the true values for <span class="math inline">\(\mathbf{b}\)</span>.</p>
<pre class="r"><code>plot(beta_true, ylab = &quot;True Value&quot;, main = &quot;Figure 7&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-14-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/c4bcd3a53e858a5bc4df18124c3d242cff1b0bad/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-14-1.png" target="_blank">c4bcd3a</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/23eac4fe33dc8feacf7b074a8c6492003d934bf4/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-14-1.png" target="_blank">23eac4f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/5f4bc45f8d6cec4103656bc39056a3532277906a/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-14-1.png" target="_blank">5f4bc45</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
</tbody>
</table>
<p></details></p>
<p>The 3rd and 6th are around -1.3, and the 5th is around 0.75.</p>
<p>Figures 8(a-c) below plots the posterior means for the 3 vectors estimated from this procedure (calculated as <span class="math inline">\(\mathbf{\bar{b}}_l := \alpha_l \circ \mu_{1l}\)</span> using <span class="math inline">\(\alpha_l, \mu_{1l}\)</span> returned from the logistic-version of the IBFS algorithm):</p>
<pre class="r"><code>b_1_post = susie.logistic.fit$post_mu[, 1] * susie.logistic.fit$post_alpha[, 1]
b_2_post = susie.logistic.fit$post_mu[, 2] * susie.logistic.fit$post_alpha[, 2]
b_3_post = susie.logistic.fit$post_mu[, 3] * susie.logistic.fit$post_alpha[, 3]

plot(b_1_post, ylab = &quot;Posterior Mean Value&quot;, main = &quot;Figure 8(a)&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-15-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-15-1.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/c4bcd3a53e858a5bc4df18124c3d242cff1b0bad/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-15-1.png" target="_blank">c4bcd3a</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/23eac4fe33dc8feacf7b074a8c6492003d934bf4/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-15-1.png" target="_blank">23eac4f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>plot(b_2_post, ylab = &quot;Posterior Mean Value&quot;, main = &quot;Figure 8(b)&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-15-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(b_3_post, ylab = &quot;Posterior Mean Value&quot;, main = &quot;Figure 8(c)&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-15-3.png" width="672" style="display: block; margin: auto;" /> We can see that the first estimated vector captures our constructed correlation between the 2nd and 3rd columns, the second estimated vector captures our constructed correlation between the 6th and 7th columns, and the third estimated vector captures the individual effect of the 5th column.</p>
<p>Figures 9(a-c) below plots our estimated PIPs, <span class="math inline">\(\alpha_1, \alpha_2, \alpha_3\)</span>:</p>
<pre class="r"><code>plot(susie.logistic.fit$post_alpha[, 1], ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 9(a)&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-16-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-16-1.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/23eac4fe33dc8feacf7b074a8c6492003d934bf4/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-16-1.png" target="_blank">23eac4f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>plot(susie.logistic.fit$post_alpha[, 2], ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 9(b)&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-16-2.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-16-2.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/23eac4fe33dc8feacf7b074a8c6492003d934bf4/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-16-2.png" target="_blank">23eac4f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>plot(susie.logistic.fit$post_alpha[, 3], ylab = &quot;Posterior Inclusion Probability&quot;, main = &quot;Figure 9(c)&quot;, pch = 19)</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-16-3.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-16-3.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/23eac4fe33dc8feacf7b074a8c6492003d934bf4/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-16-3.png" target="_blank">23eac4f</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-06
</td>
</tr>
</tbody>
</table>
<p></details></p>
<p>These groups of correlated predictors are shows from the PIPs.</p>
</div>
<div id="hard-demonstration" class="section level2">
<h2>Hard Demonstration</h2>
<p>As a hard demonstration, let <span class="math inline">\(n = 1,000, p = 100, L = 10, \sigma_0^2 = 5\)</span>.</p>
<p>We create the data <span class="math inline">\(\mathbf{X}\)</span> where all entries are iid standard normal. I then set the 2nd column to be identical to the 1st, the 88th column identical to the 87th, and the 89th column highly negatively correlated with the 87th (when running this simulation, <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_87\)</span> were generated to be non-zero, and <span class="math inline">\(b_2\)</span>, <span class="math inline">\(b_{88}\)</span> and <span class="math inline">\(b_{89}\)</span> were generated to be 0, so this was done in the spirit of the toy example from the paper).</p>
<p>We then simulated <span class="math inline">\(\mathbf{y}\)</span> from the specified bernoulli model, <span class="math display">\[
y_i \stackrel{\perp}{\sim} \text{Bern}\Bigg(\frac{e^{(\mathbf{Xb})_i}}{1 + e^{(\mathbf{Xb})_i}}\Bigg)
\]</span></p>
<pre class="r"><code>set.seed(1138)

n = 1000
p = 100
L = 10
pi = rep(1 / p, p) # prior weights
V = 5 # prior variance

beta_true = rep(0, p)
for (l in 1:L) {
  b_l = rnorm(1, 0, sqrt(V))
  gamma_l = rmultinom(1, 1, pi)
  beta_l = b_l * gamma_l
  beta_true = beta_true + beta_l
}

# simulate data, induce correlations
X = matrix(rnorm(n*p, 0, 1), nrow = n, ncol = p)
X[, 2] = X[, 1]
X[, 88] = X[, 87]
X[, 89] = runif(n, -1, -.7) * X[, 87]

# make response
Y = rbinom(n, 1, exp(X %*% beta_true + 2) / (1 + exp(X %*% beta_true + 2)))

susie.logistic.fit = susie_logistic(Y, X, L, V)</code></pre>
<p>Figure 10 below plots the true values for <span class="math inline">\(\mathbf{b}\)</span> (the numbers correspond to the points and indices of non-zero true effects).</p>
<pre class="r"><code>plot(beta_true[beta_true == 0] ~ which(beta_true == 0), xlim = c(0, 101), ylim = range(beta_true) + c(-.1, .1), xlab = &quot;Index&quot;, ylab = &quot;True Value&quot;, main = &quot;Figure 10&quot;, pch = 19)
text(which(beta_true != 0), beta_true[beta_true != 0], labels = which(beta_true != 0))</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-18-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-18-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-18-1.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
</tbody>
</table>
<p></details></p>
<p>We can see that true effects 41 and 56 are very small, and 27, 60, and 87 are also small-ish.</p>
<p>Figures 11(a-j) below plots the posterior means for the 10 vectors estimated from this procedure (calculated as <span class="math inline">\(\mathbf{\bar{b}}_l := \alpha_l \circ \mu_{1l}\)</span> using <span class="math inline">\(\alpha_l, \mu_{1l}\)</span> returned from the logistic-version of the IBFS algorithm):</p>
<pre class="r"><code>par(mfrow = c(5, 2))
for (l in 1:L) {
  b_l_post = susie.logistic.fit$post_mu[, l] * susie.logistic.fit$post_alpha[, l]
  plot(b_l_post[abs(b_l_post) &lt; .01] ~ which(abs(b_l_post) &lt; .01), xlim = c(0, 101), ylim = range(b_l_post) + c(-.1, .1), xlab = &quot;Index&quot;, ylab = &quot;Posterior Mean Value&quot;, main = paste(&quot;Figure 11(&quot;, letters[l], &quot;)&quot;, sep = &quot;&quot;), pch = 19)
  text(which(abs(b_l_post) &gt;= .01), b_l_post[abs(b_l_post) &gt;= .01], labels = which(abs(b_l_post) &gt;= .01))
}</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-19-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-19-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/andrewg3311/susieR_logistic_wflow/blob/11114f57beb0cfea2663f8b70b2178dce5df11d5/docs/figure/susie_logistic_demonstration.Rmd/unnamed-chunk-19-1.png" target="_blank">11114f5</a>
</td>
<td style="text-align:left;">
Andrew Goldstein
</td>
<td style="text-align:left;">
2018-12-08
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>(NOTE: In figures 11(a) and 11(h), 1 and 2 are close together, so it looks like the number 12. But it is really just 1 and 2).</p>
<p>We can see that the first estimated vector (11a) (and 8th, 11(h)) captures our constructed correlation between the 1st and 2nd columns, and 7th vector (11g) captures our constructed correlation between the 87th, 88th, and 89th columns (note the signs: 89 was constructed to be negatively correlated with the true effect column 87).</p>
<p>We also see that the groups (1, 2) and (76) are each captured twice, lending to their large coefficients. As a result, we have not captured the true (small) effects from 41 and 56.</p>
<p>Figures 12(a-j) below plots our estimated PIPs, <span class="math inline">\(\alpha_1, \alpha_2, \alpha_3\)</span>:</p>
<pre class="r"><code>par(mfrow = c(5, 2))
for (l in 1:L) {
  alpha_l = susie.logistic.fit$post_alpha[, l]
  plot(alpha_l[alpha_l &lt; .01] ~ which(alpha_l &lt; .01), xlim = c(0, 101), ylim = c(0, 1), xlab = &quot;Index&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = paste(&quot;Figure 12(&quot;, letters[l], &quot;)&quot;, sep = &quot;&quot;), pch = 19)
  text(which(alpha_l &gt;= .01), alpha_l[alpha_l &gt;= .01], labels = which(alpha_l &gt;= .01))
}</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>These groups of correlated predictors are shows from the PIPs.</p>
</div>
<div id="signal-level-testing" class="section level2">
<h2>Signal Level Testing</h2>
<p>In this section, I keep the same model matrix <span class="math inline">\(X\)</span>, but center and scale the columns to have unit 2-norm. I then set a single non-zero effect with a range of signal levels (<span class="math inline">\(\sigma_0^2\)</span>) to see at what levels the signal can be found. I also set another column of X to be highly positively correlated with the true effect column.</p>
<p>I have set <span class="math inline">\(n = 1000, p = 10, L = 1\)</span>.</p>
<p>Here, I always set the first element to be non-zero, and the 5th column to be correlated with the 1st.</p>
<p>At each signal level <span class="math inline">\(\sigma_0^2 \in \{1, 5, 10, 25, 50\}\)</span>, I replicate <span class="math inline">\(B = 10\)</span> times the following procedure:</p>
<ol style="list-style-type: decimal">
<li><p>Draw <span class="math inline">\(b_1 \sim \mathcal{N}(0, \sigma_0^2)\)</span>;</p></li>
<li><p>Simulate <span class="math inline">\(Y_i \sim \text{Bern}\Bigg(\frac{e^{x_i^T b}}{1 + e^{x_i^T b}}\Bigg)\)</span>;</p></li>
<li><p>Run the logistic version of SuSiE with an intercept on the data with the noise level fixed and known.</p></li>
</ol>
<p>In the plots below, the first set of 5 show the posterior mean values, <span class="math inline">\(\mu_{1} \circ \alpha\)</span>. For indices where the PIP, <span class="math inline">\(\alpha_j\)</span>, was <span class="math inline">\(\ge 0.05\)</span>, I show the point as its index number (ideally, we would only see 1 and 5). Otherwise, the point is a dot.</p>
<p>The second set of 5 show the PIPs, again with a number if the PIP was <span class="math inline">\(\ge 0.05\)</span>.</p>
<pre class="r"><code>set.seed(1138)
B = 10 # times to repeat at each noise level

n = 1000
p = 10
L = 1

X = matrix(rnorm(n*p, 0, 1), nrow = n, ncol = p)
X[, 5] = runif(n, .7, 1) * X[, 1]

X = apply(X, MARGIN = 2, function(x) x - mean(x))
X = apply(X, MARGIN = 2, function(x) x / norm(x, &quot;2&quot;))

beta_true = rep(0, p)

Vs = c(1, 5, 10, 25, 50)
beta_true_1 = matrix(nrow = length(Vs), ncol = B)
susie.logistic.list = list()
for (i in 1:length(Vs)) {
  V = Vs[i]
  susie.logistic.list[[i]] = list()
  names(susie.logistic.list)[i] = paste(&quot;Vs_&quot;, V, sep = &quot;&quot;)
  for (j in 1:B) {
    beta_true[1] = rnorm(1, 0, sqrt(V))
    Y = rbinom(n, 1, exp(X %*% beta_true) / (1 + exp(X %*% beta_true)))
    susie.logistic.list[[i]][[j]] = susie_logistic(Y, X, L, V)
    beta_true_1[i, j] = beta_true[1]
  }
}

par(mfrow = c(5, 2))
for (i in 1:length(Vs)) {
  V = Vs[i]
  for (j in 1:B) {
    a_l_post = susie.logistic.list[[i]][[j]]$post_alpha[, 1]
    b_l_post = susie.logistic.list[[i]][[j]]$post_mu[, 1] * a_l_post
    plot(b_l_post[abs(a_l_post) &lt; .05] ~ which(abs(a_l_post) &lt; .05), xlim = c(1, 10), ylim = range(b_l_post) + c(-.1, .1), xlab = &quot;Index&quot;, ylab = &quot;Posterior Mean Value&quot;, main = paste(&quot;True effect 1: &quot;, round(beta_true_1[i, j], 2), &quot; ::: Signal Level: &quot;, round(V, 2), sep = &quot;&quot;), pch = 19)
    text(which(abs(a_l_post) &gt;= .05), b_l_post[abs(a_l_post) &gt;= .05], labels = which(abs(a_l_post) &gt;= .05))
  }
}</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-1.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-2.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-3.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-4.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-5.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))


par(mfrow = c(5, 2))
for (i in 1:length(Vs)) {
  V = Vs[i]
  for (j in 1:B) {
    a_l_post = susie.logistic.list[[i]][[j]]$post_alpha[, 1]
    plot(a_l_post[abs(a_l_post) &lt; .05] ~ which(abs(a_l_post) &lt; .05), xlim = c(1, 10), ylim = c(0, 1), xlab = &quot;Index&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = paste(&quot;True effect 1: &quot;, round(beta_true_1[i, j], 2), &quot; ::: Signal Level: &quot;, round(V, 2), sep = &quot;&quot;), pch = 19)
    text(which(abs(a_l_post) &gt;= .05), a_l_post[abs(a_l_post) &gt;= .05], labels = which(abs(a_l_post) &gt;= .05))
  }
}</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-6.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-7.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-8.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-9.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-21-10.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>As we can see, we require relatively large effects in order to determine that 1 and/or 5 is contributing to the response. However, a regular logistic regression on the columns of X (removing the 5th column) in these settings also have a difficult time determing that the 1 is the effect variable.</p>
</div>
<div id="signal-testing-with-genotype-matrix" class="section level2">
<h2>Signal Testing with Genotype Matrix</h2>
<p>Here, I perform a similar test as above, except the design matrix has columns whose entries are <span class="math inline">\(X_{ij} \in \{0, 1, 2\}\)</span>. I do not center or scale these variables. As before, the 1st effect is always the only non-null effect. And the 5th column is highly positively correlated with the 1st (w.p. 0.9, it copies column 1, otherwise it is random).</p>
<p>Here, we test <span class="math inline">\(\sigma_0^2 \in \{1, 2, 3, 4, 5\}\)</span></p>
<pre class="r"><code>set.seed(1138)
B = 10 # times to repeat at each noise level

n = 1000
p = 10
L = 1

X = matrix(rbinom(n * p, 2, runif(n * p)), nrow = n, ncol = p)
copy_ind = runif(n, 0, 1) &lt;= 0.9
X[copy_ind, 5] = X[copy_ind, 1]

beta_true = rep(0, p)

Vs = 1:5
beta_true_1 = matrix(nrow = length(Vs), ncol = B)
susie.logistic.list = list()
for (i in 1:length(Vs)) {
  V = Vs[i]
  susie.logistic.list[[i]] = list()
  names(susie.logistic.list)[i] = paste(&quot;Vs_&quot;, V, sep = &quot;&quot;)
  for (j in 1:B) {
    beta_true[1] = rnorm(1, 0, sqrt(V))
    Y = rbinom(n, 1, exp(X %*% beta_true) / (1 + exp(X %*% beta_true)))
    susie.logistic.list[[i]][[j]] = susie_logistic(Y, X, L, V)
    beta_true_1[i, j] = beta_true[1]
  }
}

par(mfrow = c(5, 2))
for (i in 1:length(Vs)) {
  V = Vs[i]
  for (j in 1:B) {
    a_l_post = susie.logistic.list[[i]][[j]]$post_alpha[, 1]
    b_l_post = susie.logistic.list[[i]][[j]]$post_mu[, 1] * a_l_post
    plot(b_l_post[abs(a_l_post) &lt; .05] ~ which(abs(a_l_post) &lt; .05), xlim = c(1, 10), ylim = range(b_l_post) + c(-.1, .1), xlab = &quot;Index&quot;, ylab = &quot;Posterior Mean Value&quot;, main = paste(&quot;True effect 1: &quot;, round(beta_true_1[i, j], 2), &quot; ::: Signal Level: &quot;, round(V, 2), sep = &quot;&quot;), pch = 19)
    text(which(abs(a_l_post) &gt;= .05), b_l_post[abs(a_l_post) &gt;= .05], labels = which(abs(a_l_post) &gt;= .05))
  }
}</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-2.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-3.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-4.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-5.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))


par(mfrow = c(5, 2))
for (i in 1:length(Vs)) {
  V = Vs[i]
  for (j in 1:B) {
    a_l_post = susie.logistic.list[[i]][[j]]$post_alpha[, 1]
    plot(a_l_post[abs(a_l_post) &lt; .05] ~ which(abs(a_l_post) &lt; .05), xlim = c(1, 10), ylim = c(0, 1), xlab = &quot;Index&quot;, ylab = &quot;Posterior Inclusion Probability&quot;, main = paste(&quot;True effect 1: &quot;, round(beta_true_1[i, j], 2), &quot; ::: Signal Level: &quot;, round(V, 2), sep = &quot;&quot;), pch = 19)
    text(which(abs(a_l_post) &gt;= .05), a_l_post[abs(a_l_post) &gt;= .05], labels = which(abs(a_l_post) &gt;= .05))
  }
}</code></pre>
<p><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-6.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-7.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-8.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-9.png" width="672" style="display: block; margin: auto;" /><img src="figure/susie_logistic_demonstration.Rmd/unnamed-chunk-22-10.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>We can see that much smaller effects are detectable in this setting than above, with an arbitrary center and scaled design matrix <span class="math inline">\(X\)</span>.</p>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] workflowr_1.1.1   Rcpp_1.0.0        codetools_0.2-15 
 [4] digest_0.6.18     rprojroot_1.3-2   R.methodsS3_1.7.1
 [7] backports_1.1.2   git2r_0.23.0      magrittr_1.5     
[10] evaluate_0.11     stringi_1.2.4     whisker_0.3-2    
[13] R.oo_1.22.0       R.utils_2.7.0     rmarkdown_1.10   
[16] tools_3.5.1       stringr_1.3.1     yaml_2.2.0       
[19] compiler_3.5.1    htmltools_0.3.6   knitr_1.20       </code></pre>
</div>
</div>

<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

<hr>
<p>
  This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a>
  analysis was created with
  <a href="https://github.com/jdblischak/workflowr">workflowr</a> 1.1.1
</p>
<hr>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
